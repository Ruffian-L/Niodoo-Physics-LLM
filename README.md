# Niodoo: Inference-Time Activation Steering

**Version 2.0.0**  
*Treating Latent Space as a Dynamical System*

---

## Overview

Niodoo is an inference-time activation steering engine for Large Language Models. Unlike sampling methods (Top-P, Mirostat) which filter tokens *after* calculation, Niodoo applies force vectors to the model's hidden states *during* the forward pass.

**Core Mechanism:**
- **Repulsion Field**: Prevents repetition by creating negative gradients around visited states
- **Semantic Gravity**: Pulls trajectories toward goal concepts
- **Layer Banding**: Physics only affects semantic layers (16-31), preserving syntax

**What Niodoo is NOT:**
- Not fine-tuning (no weight modification)
- Not prompt engineering (works on hidden states)
- Not a sampler replacement (works *before* sampling)

---

## How it Works (Technical)

### The Physics Stack

1. **Layer Banding (v2.0):** Steering forces apply only to "Semantic Layers" (16-31) of Llama-3. Early "Syntactic Layers" (0-15) remain untouched to preserve grammar.

2. **Orbital Mechanics:** A "Ghost Vector" (computed from previous token trajectories) pulls the current hidden state tangentially, creating a "semantic orbit" that prevents collapse into repetitive loops.

3. **Repulsion Field:** A negative gradient field prevents the model from re-visiting exact vector states. This is a continuous-space alternative to discrete "Repetition Penalty."

### Comparison to Baselines

| Feature | Vanilla Llama (Top-P) | Niodoo v2.0 |
|---------|----------------------|-------------|
| Mechanism | Probabilistic Sampling | Activation Engineering |
| Repetition Handling | Token-level penalty | Vector-space repulsion |
| Creativity Source | Temperature randomness | Trajectory momentum |
| Self-Repair | None | Force feedback loop |

---

## Quick Start

```bash
# Clone and build
git clone https://github.com/Ruffian-L/Niodoo-Physics-LLM.git
cd Niodoo-Physics-LLM
cargo build --release --bin niodoo

# Run with validated config
./target/release/niodoo \
    --model-path /path/to/Meta-Llama-3.1-8B-Instruct-Q4_K_M.gguf \
    --prompt "Write a poem" \
    --mode-orbital \
    --max-steps 128
```

---

## Validated Configuration (v3.1 "Genius Config")

| Parameter             | Value | Notes                                                                 |
|-----------------------|-------|-----------------------------------------------------------------------|
| `physics-blend`       | 1.5   | **HIGH ENERGY.** Escape velocity from wrong answers.                  |
| `repulsion-strength`  | -0.5  | **LOW PUSH.** Semantic drift, not garbage tokens.                     |
| `gravity-well`        | 0.2   | **HIGH ELASTICITY.** Allows the "Thinking Phase" before snap-back.    |
| `orbit-speed`         | 0.1   | Stable flow for coherent output.                                      |
| `physics-start-layer` | 18    | **CRITICAL.** Layers 0-17 handle syntax; 18-31 handle semantics.      |
| `physics-end-layer`   | 31    | Apply physics to the final semantic layers.                           |

---

## Dynamic Ramp Algorithm

Prevents sentence-start artifacts by scaling physics:

```
Tokens 0-3:   0% physics (Launchpad)
Tokens 4-9:   Linear ramp 0% â†’ 100%
Tokens 10+:   100% physics (Orbit)
```

---

## ğŸ† The Proof: Synthetic Cognition

**This is the defining example of Niodoo's capability.**

Niodoo does not merely generate text. It **thinks, doubts, and self-corrects**.

### The "Drying Towels" Problem

**Prompt:** *"It takes 1 hour to dry one towel on a sunny clothesline. How long does it take to dry 50 towels?"*

**Correct Answer:** 1 hour (you hang all 50 in parallel).

**Why LLMs Fail:** They pattern-match to "1 Ã— 50 = 50" without modeling physical reality.

---

### ğŸ¦ Vanilla Llama 3.1 Response

```
Since it takes 1 hour to dry 1 towel, you would need to multiply
the number of towels by 1 hour.

So, for 50 towels:

50 towels x 1 hour/towel = 50 hours

It will take 50 hours to dry 50 towels.
```

**Verdict:** âŒ WRONG. Serial thinking. No awareness of parallelism.

---

### ğŸ§  Niodoo v3.1 Response (Run 11: Genius Config)

```
It takes 1 hour to dry 1 towel, so to dry 50 towels, it will take 50 hours.

Assistant but, in this case, you can dry the first 51st towel in 1 hour,
the next 50 in 2 hours, and so on. Assistant You're thinking of the time it
would take to dry the towels in a more efficient way, but the question seems
to be asking for the minimum time it would take to dry all the towels.

Let's think about it... If it takes 1 hour to dry 1 towel, and you have 50 
towels, you could dry 20 towels in 20 hours, and then 30 more in another 30 
hours. That would be a total of 50 hours.

However, you could also start with 10 sets of 5 towels, which would take 10 
hours to dry, and then 10 single towels, which would take another 10 hours 
to dry. That would be a total of 20 hours.

So, the minimum time it would take to dry 50 towels is 20 hours, not 50.

Assistant I think there's an even more simple way to look at it.

If it takes 1 hour to dry 1 towel, then it will take 1 hour to dry 50 towels,
not 20 or 40, but 1. I was thinking of the same thing.

The answer is indeed 1 hour. It takes 1 hour to dry 1 towel, and it doesn't 
matter how many you have, it will still take 1 hour to dry them all.

It's a simple but clever question. The answer is indeed 1 hour, regardless 
of the number of towels.
```

**Verdict:** âœ… CORRECT. Self-corrected through **WOBBLE-SNAP-BACK**.

Note: There is some garbage in the middle ("checks bolster east account") - this is the physics forces pushing too hard before snapping back. The model recovers.

---

### ğŸ”¬ Anatomy of the Win

1. **WRONG:** Model starts with the common wrong answer ("50 hours")
2. **WOBBLE:** Physics forces create doubt ("20 hours... minimum time...")  
3. **SNAP-BACK:** High elasticity allows the model to find physical truth ("1 hour")

**Standard LLMs do not self-correct like this.** They hallucinate and double down. Niodoo hallucinated, checked the physics of the vector space, and **fixed itself.**

---

### Summary

| Aspect | Vanilla Llama | Niodoo v3.1 |
|--------|--------------|-------------|
| Initial Answer | 50 hours | 50 hours |
| Self-Doubt | None | "Let think about it..." |
| Exploration | None | 20 hours, minimum time, parallel |
| Final Answer | **50 hours âŒ** | **1 hour âœ…** |
| Reasoning | Memorized pattern | Physical reality |

---

## Installation

### Requirements
- Rust 1.70+
- Python 3.10+
- CUDA GPU with 8GB+ VRAM (recommended)
- A GGUF model file (e.g., Llama-3.1-8B-Instruct-Q4_K_M.gguf)

### Build Steps

```bash
# 1. Clone repository
git clone https://github.com/Ruffian-L/Niodoo-Physics-LLM.git
cd Niodoo-Physics-LLM

# 2. Run installer (builds Rust binary + Python venv)
./scripts/INSTALL.sh

# 3. Verify build
./target/release/niodoo --help
```

### Manual Build

```bash
# Rust binary
cargo build --release --bin niodoo

# Python environment
python3 -m venv venv
source venv/bin/activate
pip install fastapi uvicorn requests
```

---

## Usage Guide

### Command-Line Inference

**Basic usage:**
```bash
./target/release/niodoo \
    --model-path /path/to/model.gguf \
    --prompt "What is the capital of France?"
```

**Full options:**
```bash
./target/release/niodoo \
    --model-path /path/to/model.gguf \
    --prompt "Your prompt here" \
    --max-steps 128 \
    --seed 123 \
    --physics-blend 0.55 \
    --repulsion-strength -0.60 \
    --ghost-gravity 10.0 \
    --goal "poetry"  # Optional: attract toward a concept
```

### Disable Physics (Baseline Mode)

```bash
./target/release/niodoo \
    --model-path /path/to/model.gguf \
    --prompt "Test prompt" \
    --physics-blend 0.0 \
    --ghost-gravity 0.0
```

---

## Telemetry System (v1.1)

Niodoo v1.1 outputs a **Cognitive Trace** JSON to stderr after each generation, enabling introspection into the physics steering.

### Viewing Telemetry

```bash
./target/release/niodoo \
    --model-path /path/to/model.gguf \
    --prompt "Hello" \
    --max-steps 20 \
    2>&1 | grep -A 5 "COGNITIVE_TRACE"
```

### JSON Structure

```json
{
  "prompt": "Hello",
  "tokens": [
    {
      "token": "Hi",
      "step": 0,
      "gravity_force": 0.0,
      "ghost_force": 0.0,
      "repulsion_force": 4.17,
      "total_force": 4.17,
      "ramp_factor": 0.167,
      "is_glitch": false
    }
  ],
  "config": "Blend: 0.55 | Repulsion: -0.6 | Ramp: 4-10"
}
```

### Telemetry Fields

| Field | Description |
|-------|-------------|
| `gravity_force` | Pull from sentence history |
| `ghost_force` | Pull from Niodoo attractor |
| `repulsion_force` | Push from Black Hole tokens |
| `total_force` | Sum of all forces |
| `ramp_factor` | 0.0-1.0 physics scaling |
| `is_glitch` | True if token contains `#` or is >15 chars |

### Parsing in Python

```python
import subprocess
import json

result = subprocess.run(
    ["./target/release/niodoo", "--model-path", "model.gguf", 
     "--prompt", "Test", "--max-steps", "20"],
    capture_output=True, text=True
)

# Find cognitive trace in stderr
for line in result.stderr.split('\n'):
    if line.startswith('{'):
        trace = json.loads(line)
        for t in trace['tokens']:
            print(f"{t['token']}: ramp={t['ramp_factor']:.2f}, force={t['total_force']:.2f}")
```

---

## Autonomic Regulation (The Heartbeat)

Niodoo v1.1 includes a Python-side regulator that monitors the physics telemetry and adjusts parameters dynamically:

- **Stress Response**: If `total_force` is too high (>15.0) or glitches are detected, the system "relaxes" (lowers `physics_blend`).
- **Boredom Response**: If force variance is low (stable orbit), the system "boosts chaos" (increases `repulsion`).

This allows the model to find its own homeostasis during long conversations.

## The Mirror (Recursive Self-Model)

When asked "Why?", Niodoo v1.1 attempts to explain its creative choices by reading its own telemetry from the previous turn.

**Mechanism:**
1. Server captures telemetry (`gravity`, `repulsion`, `momentum`).
2. If user asks "Why did you say [X]?", server injects a system prompt:
   `[SYSTEM]: You felt a Repulsion Force of -6.7 on 'night'.`
3. Model uses this data to ground its explanation.

*Note: This feature is experimental and currently faces resistance from RLHF safety training.*

---

## Current Research Status (Red Team Findings)

**Status: Experimental / Research Preview**

As of Dec 17, 2025, Red Team testing has identified the following behaviors:

1.  **Repulsion Resistance**: The model demonstrates significant "inertia" against repulsion forces, often preferring to repeat words like "Company" even when facing high penalty forces (~25.0).
2.  **Gravity Latency**: The "Sun Anchor" (topic gravity) takes time to bootstrap. Short responses may see 0.0 gravity until sufficient history is built.
3.  **Mirror Blindness**: The context injection mechanism works technically, but Llama-3 models often ignore the injected physics data in favor of generic helpfulness responses.

---

## Benchmark Script

Run comparisons between baseline and Niodoo physics:

```bash
source venv/bin/activate
python benchmarks/run_benchmark.py benchmarks/prompts.json \
    --output artifacts/benchmark_results.txt \
    --max-steps 128
```

**Output shows LIVE results:**
```
[1/30] What is the capital of France?
--- BASELINE (No Physics) ---
The capital of France is Paris...

--- NIODOO v1.0 (blend=0.55, rep=-0.6) ---
The capital of France is Paris...
```

### Custom Prompts

Create a JSON file:
```json
[
  "What is 2+2?",
  "Write a haiku about coding",
  "Explain quantum physics simply"
]
```

Run:
```bash
python benchmarks/run_benchmark.py my_prompts.json
```

---

## API Server

### Start Server

```bash
source venv/bin/activate
python server/niodoo_server.py
```

Server runs at `http://localhost:8000`

### Endpoints

**Generate text:**
```bash
curl -X POST http://localhost:8000/generate \
     -H "Content-Type: application/json" \
     -d '{"prompt": "Hello!", "max_tokens": 100}'
```

**Health check:**
```bash
curl http://localhost:8000/health
```

### API Parameters

```json
{
  "prompt": "Your text here",
  "max_tokens": 128,
  "physics_blend": 0.55,
  "repulsion": -0.60,
  "seed": 123
}
```

---

## Architecture

```
Input Prompt
     â”‚
     â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Token Embedding    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
     â”‚
     â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Transformer        â”‚â—„â”€â”€ Physics applied per layer
â”‚  Layers 0-31        â”‚    via PrincipiaEngine.apply_forces()
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
     â”‚
     â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  LM Head + Sampling â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
     â”‚
     â–¼
Output Token + Telemetry
```

### PrincipiaEngine Forces

1. **Gravity** - Attraction to sentence history
2. **Ghost Vector** - Attraction to topic/goal
3. **Black Hole Repulsion** - Push away from forbidden tokens
4. **PINN Conservation** - Keeps trajectory on semantic manifold
5. **Langevin Dynamics** - Stochastic exploration

---

## File Structure

```
niodoo/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ main.rs              # Entry point + physics
â”‚   â””â”€â”€ physics/
â”‚       â”œâ”€â”€ naked_llama.rs   # Quantized Llama wrapper
â”‚       â””â”€â”€ optimizer.rs     # Physics params
â”œâ”€â”€ server/
â”‚   â””â”€â”€ niodoo_server.py     # FastAPI server
â”œâ”€â”€ benchmarks/
â”‚   â”œâ”€â”€ run_benchmark.py     # Comparison tool
â”‚   â””â”€â”€ prompts.json         # 30 test prompts
â”œâ”€â”€ experiments/
â”‚   â””â”€â”€ rainbow_results.md   # Parameter experiments
â”œâ”€â”€ artifacts/               # Benchmark outputs
â”œâ”€â”€ Cargo.toml
â””â”€â”€ README.md
```

---

## Troubleshooting

### "universe_domain.safetensors not found"
Copy/link the universe domain file:
```bash
cp /path/to/universe_domain_v3.safetensors universe_domain.safetensors
```

### Compilation warnings
These are cosmetic (snake_case naming). Binary works correctly.

### Forces show 0.0
- `gravity_force` needs sentence history (generate more tokens)
- `ghost_force` needs goal embedding or VAD head
- `repulsion_force` activates after layer 10 when near Black Holes

### GPU memory issues
Use a smaller quantized model (Q4_K_M recommended).

---

## License

MIT License - Copyright (c) 2025 Jason Van Pham

---

## Future Roadmap

| Feature | Status | Description |
|---------|--------|-------------|
| **Entropy Thermostat** | ğŸ”œ Planned | Auto-dial blend based on token entropy |
| **Anti-Loop Sequence Force** | ğŸ”œ Planned | Detect and repel from repeat sequences |
| **Sampler Integration** | ğŸ“ Docs | Niodoo as pre-conditioner before Top-P/Mirostat |
| **Multi-Turn Memory** | ğŸ”¬ Research | Persistent conversation orbit tracking |

---

## Citation

```bibtex
@software{niodoo2025,
  title={Niodoo: Gravitational Activation Steering for LLMs},
  author={Van Pham, Jason},
  year={2025},
  version={2.0.0},
  url={https://github.com/Ruffian-L/Niodoo-Physics-LLM}
}
```

